{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "sys.path.append(\"../scripts\")\n",
    "from joinfiles import JoinFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correccion de datos\n",
    "\n",
    "en base a los errores identificados, realizare una limpieza de datos buscando conservar la mayor cantidad de archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos los nombres de los archivos con problemas y los errores asociados\n",
    "data_path = \"../data\"\n",
    "files = np.load(data_path + \"/bad_files.npy\")\n",
    "errors = np.load(data_path + \"/errors.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion de headers\n",
    "\n",
    "corregido manualmente, son archivos excel donde por interaccion humana se modifico su estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luego de la correccion...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "error_type = \"ERROR.badHeader\"\n",
    "idxs = np.where(errors == error_type)[0]\n",
    "for idx in idxs:\n",
    "    print(files[idx])\n",
    "    \n",
    "print(\"luego de la correccion...\")\n",
    "\n",
    "for idx in idxs:\n",
    "    df = pd.read_excel(files[idx])\n",
    "    print(df.columns)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcion de formato\n",
    "\n",
    "varios archivos que no pudieron ser leidos es porque fueron mal pasados, pero algunos presentan solo un error de formato, siendo .csv pero con extension .xls\n",
    "Los archivos malos son borrados y los con error de formato son corregidos (pasados a excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "luego de la correccion...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_type = \"ERROR.file\"\n",
    "idxs = np.where(errors == error_type)[0]\n",
    "for idx in idxs:\n",
    "    print(files[idx])\n",
    "    \n",
    "print(\"\\n\\nluego de la correccion...\\n\")\n",
    "\n",
    "ffs = []\n",
    "for idx in idxs:\n",
    "    f = files[idx]\n",
    "    f = f[:len(f) - 4]\n",
    "    f += \".csv\"\n",
    "    if os.path.exists(f):\n",
    "        print(f + \": FORMATEADO A .csv\")\n",
    "        ffs.append(f)\n",
    "    else:\n",
    "        print(f + \": BORRADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion de archivo vacio\n",
    "\n",
    "estos directamente son borrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "luego de la correccion...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_type = \"ERROR.NoResultFile\"\n",
    "\n",
    "idxs = np.where(errors == error_type)[0]\n",
    "for idx in idxs:\n",
    "    print(files[idx])\n",
    "\n",
    "print(\"\\n\\nluego de la correccion...\\n\")\n",
    "\n",
    "for idx in idxs:\n",
    "    f = files[idx]\n",
    "    if not os.path.exists(f):\n",
    "        print(f + \": BORRADO\")\n",
    "    else:\n",
    "        print(f + \": FALTA POR SER BORRADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion de archivo con NaN\n",
    "\n",
    "se borran las filas con problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_type = \"ERROR.NaN\"\n",
    "\n",
    "idxs = np.where(errors == error_type)[0]\n",
    "for idx in idxs:\n",
    "    print(files[idx])\n",
    "    \n",
    "# borramos filas y guardamos el mismo archivo\n",
    "print(\"\\n\\n\")\n",
    "for idx in idxs:\n",
    "    f = files[idx]\n",
    "    print(\"corrigiendo file %s ...\" % f, end=\"\")\n",
    "    df = pd.read_excel(f)\n",
    "    df = df.dropna()\n",
    "    df.to_excel(f)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion de archivos con datos malos\n",
    "\n",
    "es necesario verificar la extension de dicho error. existen 3 casos:\n",
    "- la estacion presenta puros ceros porque no mide dichos valores\n",
    "- en un intervalo pequeño de un dia fallo la estacion, se descarta el intervalo\n",
    "- en un intervalo grande de un dia fallo la estacion, se descarta dia completo\n",
    "\n",
    "\n",
    "#### Arbitrariamente se elige:\n",
    "-  una estacion (un archivo que contiene 6 meses )con mas del 5% de mediciones mala signifca una mala estacion.\n",
    "- si la estacion tiene menos del 5% de datos malos, se limpian dichos datos +- 1 hora de medicion por posibles errores escondidos (+- 4 datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/PAULA/COQUIMBO/CARACHILLA/Carachilla01-01-2009-30-06-2009.csv INCONSISTENCY.ZeroOrNegPAtm\n"
     ]
    }
   ],
   "source": [
    "error_prefix = \"INCONSISTENCY\"\n",
    "\n",
    "idxs = []\n",
    "for i, err in enumerate(errors):\n",
    "    if error_prefix in err:\n",
    "        idxs.append(i)\n",
    "for idx in idxs:\n",
    "    print(files[idx], errors[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/PAULA/COQUIMBO/CARACHILLA/Carachilla01-01-2009-30-06-2009.csv archivo borrado\n"
     ]
    }
   ],
   "source": [
    "for idx in idxs:\n",
    "    f = files[idx]\n",
    "    err = errors[idx]\n",
    "    if os.path.exists(f):\n",
    "        if \".csv\" in f:\n",
    "            df = pd.read_csv(f, sep='\\t', lineterminator='\\r', decimal=\",\")\n",
    "        else:\n",
    "            df = pd.read_excel(f)\n",
    "        before = len(df)\n",
    "        if \"NegVel\" in err:\n",
    "            df2 = df[df[\"Velocidad de Viento\"] < 0]\n",
    "        elif \"NegDir\" in err:\n",
    "            df2 = df[df[\"Direccion de Viento\"] < 0]\n",
    "        elif \"NegHum\" in err:\n",
    "            df2 = df[df[\"Humedad\"] < 0]\n",
    "        elif \"ZeroOrNegPAtm\" in err:\n",
    "            df2 = df[df[\"Presion Atmosferica\"] <= 0]\n",
    "        after = len(df2)\n",
    "        if before * 0.05 < after:\n",
    "            print(f, \"se descarta archiovo\")\n",
    "            os.remove(f)\n",
    "        elif after == 0:\n",
    "            print(f, \"archivo ya corregido\")\n",
    "        else:\n",
    "            print(f, \"se borran datos\")\n",
    "            indexs = df2.index\n",
    "            idxs2 = []\n",
    "            for i in indexs:\n",
    "                idxs2.append(i)\n",
    "                for j in [1, 2, 3, 4]:\n",
    "                    left = max(0, i - j)\n",
    "                    right = min(before - 1, i + j)\n",
    "                    idxs2.extend([left, right])\n",
    "            idxs2 = np.unique(idxs2)\n",
    "            idxs2 = np.sort(idxs2)\n",
    "            df3 = df.drop(df.index[idxs2])\n",
    "            df3.to_excel(f)\n",
    "    else:\n",
    "        print(f, \"archivo borrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion de estaciones con mas de un codigo\n",
    "\n",
    "se borra la estacion completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_type = \"ERROR.notUniqueCodeInStation\"\n",
    "\n",
    "idxs = np.where(errors == error_type)[0]\n",
    "for idx in idxs:\n",
    "    print(files[idx])\n",
    "    \n",
    "\n",
    "print(\"\\n\\n\")    \n",
    "for idx in idxs:\n",
    "    f = files[idx]\n",
    "    if not os.path.exists(f):\n",
    "        print(f, \"borrado\")\n",
    "    else:\n",
    "        print(f, \"falta por borrar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion de nombres de archivos\n",
    "\n",
    "pandas tiene problemas con caracteres especiales como ñ o letras con acento. Para evitar esto, identificaremos a las regiones con nombres asi y los modificaremos:\n",
    "- quitando los acentos\n",
    "- remplazando las ñ por nh\n",
    "\n",
    "Esto se hara manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuando ya no queden problemas, este codigo no mostrara nada\n",
    "\n",
    "\n",
    "files = glob.glob(\"../data/PAULA/*/*\", recursive=True)\n",
    "stations = []\n",
    "full = []\n",
    "for f in files:\n",
    "    f = f.replace(\"\\\\\", \"/\")\n",
    "    if all(x not in f for x in [\"FDF semestre 2 2010\", \"DE MALLANES Y LA ANTARTIDA\"]):\n",
    "        stations.append(f.split(\"/\")[-1])\n",
    "        full.append(f)\n",
    "\n",
    "\n",
    "for s, f in zip(stations, full):\n",
    "    if not re.match('^[a-zA-Z0-9 -]+$', s):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de nuevo dataset\n",
    "\n",
    "se agrupan los archivos por estacion como se realizo con anterioridad.\n",
    "\n",
    "en este caso tambien tenemos que algunos archivos son .csv\n",
    "\n",
    "NOTA: caracteres especiales en el nombre del archivo producen problemas en pandas. Para evitar ello, use las estaciones como carpetas, las cuales cada una tiene 1 solo archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::::: ARICA Y PARINACOTA ::::::\n",
      "creating: ../data/cleared/ARICA Y PARINACOTA/AZAPA1.csv\n",
      "creating: ../data/cleared/ARICA Y PARINACOTA/AZAPA2.csv\n",
      "creating: ../data/cleared/ARICA Y PARINACOTA/COLONIA JFLLUTA BAJO.csv\n",
      "creating: ../data/cleared/ARICA Y PARINACOTA/PUROCHILE LLUTA MEDIO.csv\n",
      "creating: ../data/cleared/ARICA Y PARINACOTA/SOCOROMA.csv\n",
      "creating: ../data/cleared/ARICA Y PARINACOTA/TRUFA AZAPA MEDIO.csv\n",
      ":::::: ATACAMA ::::::\n",
      "creating: ../data/cleared/ATACAMA/ALTO DEL CARMEN.csv\n",
      "creating: ../data/cleared/ATACAMA/BODEGA.csv\n",
      "creating: ../data/cleared/ATACAMA/COPIAPO.csv\n",
      "creating: ../data/cleared/ATACAMA/HORNITOS.csv\n",
      "creating: ../data/cleared/ATACAMA/JOTABECHE.csv\n",
      "creating: ../data/cleared/ATACAMA/TRANQUE-LAUTARO.csv\n",
      "creating: ../data/cleared/ATACAMA/VALLENAR.csv\n",
      ":::::: AYSEN DEL GENERAL DEL C.I.CAMPO ::::::\n",
      "creating: ../data/cleared/AYSEN DEL GENERAL DEL C.I.CAMPO/AYSEN.csv\n",
      "creating: ../data/cleared/AYSEN DEL GENERAL DEL C.I.CAMPO/CHILECHICO.csv\n",
      "creating: ../data/cleared/AYSEN DEL GENERAL DEL C.I.CAMPO/COYHAIQUE.csv\n",
      ":::::: COQUIMBO ::::::\n",
      "creating: ../data/cleared/COQUIMBO/ALGARROBAL.csv\n",
      "creating: ../data/cleared/COQUIMBO/CARACHILLA.csv\n",
      "creating: ../data/cleared/COQUIMBO/COMBARBALA.csv\n",
      "creating: ../data/cleared/COQUIMBO/EL PALQUI.csv\n",
      "creating: ../data/cleared/COQUIMBO/ILLAPEL.csv\n",
      "creating: ../data/cleared/COQUIMBO/MONTE PATRIA.csv\n",
      "creating: ../data/cleared/COQUIMBO/PAIHUANO.csv\n",
      "creating: ../data/cleared/COQUIMBO/PALQUI.csv\n",
      "creating: ../data/cleared/COQUIMBO/PUNITAQUI.csv\n",
      "creating: ../data/cleared/COQUIMBO/RECOLETA.csv\n",
      "creating: ../data/cleared/COQUIMBO/SALAMANCA.csv\n",
      "creating: ../data/cleared/COQUIMBO/SAN JULIAN.csv\n",
      "creating: ../data/cleared/COQUIMBO/VICUNHA.csv\n",
      ":::::: DE LA ARAUCANIA ::::::\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/COLLIPULLI.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/CUNCO.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/FREIRE.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/GALVARINO.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/GORBEA.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/LOMCOCHE.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/NUEVA IMPERIAL.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/POCOYAN.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/PUCON.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/RENAICO.csv\n",
      "creating: ../data/cleared/DE LA ARAUCANIA/TRAIGEN.csv\n",
      ":::::: DE LOS LAGOS ::::::\n",
      "creating: ../data/cleared/DE LOS LAGOS/BUTALCURA.csv\n",
      "creating: ../data/cleared/DE LOS LAGOS/FRUTILLAR.csv\n",
      "creating: ../data/cleared/DE LOS LAGOS/OSORNO.csv\n",
      "creating: ../data/cleared/DE LOS LAGOS/PURRANQUE.csv\n",
      "creating: ../data/cleared/DE LOS LAGOS/REMAHUE.csv\n",
      "creating: ../data/cleared/DE LOS LAGOS/RIO NEGRO.csv\n",
      ":::::: DE LOS RIOS ::::::\n",
      "creating: ../data/cleared/DE LOS RIOS/LA UNION.csv\n",
      "creating: ../data/cleared/DE LOS RIOS/LA UNION NORTE.csv\n",
      "creating: ../data/cleared/DE LOS RIOS/MAFIL.csv\n",
      "creating: ../data/cleared/DE LOS RIOS/MARIQUINA.csv\n",
      "creating: ../data/cleared/DE LOS RIOS/PAILLACO.csv\n",
      "creating: ../data/cleared/DE LOS RIOS/PAILLACO NORTE.csv\n",
      "creating: ../data/cleared/DE LOS RIOS/RIO BUENO.csv\n",
      ":::::: DEL BIO BIO ::::::\n",
      "creating: ../data/cleared/DEL BIO BIO/BULNES.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/CHILLAN VIEJO.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/COIHUECO.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/LAS VINHAS.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/LOS ANGELES.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/LOS AROMOS.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/LOS CIPRESES.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/MULCHEN.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/NEGRETE.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/NHIQUEN.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/NINHUE.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/NUEVA ALDEA.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/PINTO.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/QUIHUA.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/QUILLON.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/SAN IGANACIO SUR.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/SAN IGNACIO.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/SAN NICOLAS.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/TIERRAS NOBLES.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/VALLE DEL SOL.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/VIVEROS.csv\n",
      "creating: ../data/cleared/DEL BIO BIO/YUNGAY.csv\n",
      ":::::: DEL LIBERTADOR BERNARDO OHIGGINS ::::::\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/CHEPICA.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/CHINBARONGO.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/CODEGUA.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/CODEGUA NORTE.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/CONTAUCO.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/EL CARMEN.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/EL TAMBO.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/ESTRELLA SUR.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/GRANEROS NORTE.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/LA ESTRELLA NORTE.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/LLALAGUA.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/LOLOL.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/MALLOA.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/MARCHIGUE.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/MOSTAZAL.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/NANCAGUA2.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/OLIVAR ALTO.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/PALMILLA.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/PEUMO NORTE.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/PLACILLA.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/PUNTA CORTES.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/RAPEL.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/REQUINOA.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/SAN FERNANDO.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/SAN VICENTE DE TT.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/SANTA CRUZ.csv\n",
      "creating: ../data/cleared/DEL LIBERTADOR BERNARDO OHIGGINS/STA BRISILA.csv\n",
      ":::::: DEL MAULE ::::::\n",
      "creating: ../data/cleared/DEL MAULE/CAUQUENES.csv\n",
      "creating: ../data/cleared/DEL MAULE/CHANCO.csv\n",
      "creating: ../data/cleared/DEL MAULE/COLBUN.csv\n",
      "creating: ../data/cleared/DEL MAULE/CURICO.csv\n",
      "creating: ../data/cleared/DEL MAULE/LINARES.csv\n",
      "creating: ../data/cleared/DEL MAULE/LINARES2.csv\n",
      "creating: ../data/cleared/DEL MAULE/LONGAVI NORTE.csv\n",
      "creating: ../data/cleared/DEL MAULE/LONGAVI SUR.csv\n",
      "creating: ../data/cleared/DEL MAULE/LONTUE.csv\n",
      "creating: ../data/cleared/DEL MAULE/MAULE.csv\n",
      "creating: ../data/cleared/DEL MAULE/MORZA.csv\n",
      "creating: ../data/cleared/DEL MAULE/PARRAL.csv\n",
      "creating: ../data/cleared/DEL MAULE/PARRAL NORTE.csv\n",
      "creating: ../data/cleared/DEL MAULE/PENCAHUE.csv\n",
      "creating: ../data/cleared/DEL MAULE/PETEROA.csv\n",
      "creating: ../data/cleared/DEL MAULE/RAUCO.csv\n",
      "creating: ../data/cleared/DEL MAULE/ROBLES DEL MAULE.csv\n",
      "creating: ../data/cleared/DEL MAULE/SAGRADA FAMILIA 1.csv\n",
      "creating: ../data/cleared/DEL MAULE/SAN JAVIER.csv\n",
      "creating: ../data/cleared/DEL MAULE/SAN RAFAEL.csv\n",
      "creating: ../data/cleared/DEL MAULE/TENO.csv\n",
      "creating: ../data/cleared/DEL MAULE/TRES ESQUINAS.csv\n",
      "creating: ../data/cleared/DEL MAULE/VICHUQUEN.csv\n",
      "creating: ../data/cleared/DEL MAULE/VILLA ALEGRE.csv\n",
      "creating: ../data/cleared/DEL MAULE/YERBAS BUENAS.csv\n",
      ":::::: METROPOLITANA ::::::\n",
      "creating: ../data/cleared/METROPOLITANA/ALHUE.csv\n",
      "creating: ../data/cleared/METROPOLITANA/BUIN.csv\n",
      "creating: ../data/cleared/METROPOLITANA/CALERA DE TANGO.csv\n",
      "creating: ../data/cleared/METROPOLITANA/CHOCALAN.csv\n",
      "creating: ../data/cleared/METROPOLITANA/CURACAVI.csv\n",
      "creating: ../data/cleared/METROPOLITANA/EL MONTE.csv\n",
      "creating: ../data/cleared/METROPOLITANA/HUELQUEN.csv\n",
      "creating: ../data/cleared/METROPOLITANA/ISLA DE MAIPO.csv\n",
      "creating: ../data/cleared/METROPOLITANA/LA PINTANA.csv\n",
      "creating: ../data/cleared/METROPOLITANA/LAMPA.csv\n",
      "creating: ../data/cleared/METROPOLITANA/LEYDA.csv\n",
      "creating: ../data/cleared/METROPOLITANA/LO HERRERA.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: ../data/cleared/METROPOLITANA/MALLARAUCO.csv\n",
      "creating: ../data/cleared/METROPOLITANA/MELIPILLA.csv\n",
      "creating: ../data/cleared/METROPOLITANA/PIRQUE.csv\n",
      "creating: ../data/cleared/METROPOLITANA/SAN PEDRO.csv\n",
      "creating: ../data/cleared/METROPOLITANA/TALAGANTE.csv\n",
      "creating: ../data/cleared/METROPOLITANA/TILTIL.csv\n",
      ":::::: VALPARAISO ::::::\n",
      "creating: ../data/cleared/VALPARAISO/CABILDO.csv\n",
      "creating: ../data/cleared/VALPARAISO/CALLELARGA.csv\n",
      "creating: ../data/cleared/VALPARAISO/CASA BLANCA.csv\n",
      "creating: ../data/cleared/VALPARAISO/CATEMU.csv\n",
      "creating: ../data/cleared/VALPARAISO/HIJUELAS.csv\n",
      "creating: ../data/cleared/VALPARAISO/LA CRUZ.csv\n",
      "creating: ../data/cleared/VALPARAISO/LIMACHE.csv\n",
      "creating: ../data/cleared/VALPARAISO/LLAY-LLAY.csv\n",
      "creating: ../data/cleared/VALPARAISO/LOS ANDES.csv\n",
      "creating: ../data/cleared/VALPARAISO/NOGALES.csv\n",
      "creating: ../data/cleared/VALPARAISO/OLMUE.csv\n",
      "creating: ../data/cleared/VALPARAISO/PANQUEHUE.csv\n",
      "creating: ../data/cleared/VALPARAISO/PETORCA.csv\n",
      "creating: ../data/cleared/VALPARAISO/PUTAENDO.csv\n",
      "creating: ../data/cleared/VALPARAISO/QUILLOTA.csv\n",
      "creating: ../data/cleared/VALPARAISO/RINCONADA.csv\n",
      "creating: ../data/cleared/VALPARAISO/SAN FELIPE.csv\n",
      "creating: ../data/cleared/VALPARAISO/SANTA MARIA.csv\n"
     ]
    }
   ],
   "source": [
    "raw = data_path + \"/PAULA\"\n",
    "cleared = data_path + \"/cleared\"\n",
    "jf = JoinFiles(raw, cleared)\n",
    "jf.process_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificacion de nuevo dataset\n",
    "\n",
    "verificamos que se hayan corregido todos los errores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from badfiles import BadFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data_path = \"../data/cleared\"\n",
    "\n",
    "bf = BadFiles(raw_data_path)\n",
    "bf.recheck_all()\n",
    "# no muestra nada si esta todo ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
